{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPTCL+C/uHyoYIN6FfJXuJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luimui/AI3-NN-SS24/blob/main/nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6X4Q8SoHn_la"
      },
      "outputs": [],
      "source": [
        "# https://github.com/karpathy/ng-video-lecture\n",
        "# https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt', allow_redirects=True)\n",
        "\n",
        "text = response.text\n",
        "\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'vocab_size: {vocab_size}')\n",
        "print(''.join(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWJTni1sp1fp",
        "outputId": "5262724a-e2da-4068-f796-7c0ee4b976cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size: 65\n",
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(f'encode - hi there: {encode(\"hi there\")}')\n",
        "print(f'decode - {encode(\"hi there\")}: {decode(encode(\"hi there\"))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9hI7lnp8zl",
        "outputId": "84685a6c-831c-4e54-e01a-db3ae7166151"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encode - hi there: [46, 47, 1, 58, 46, 43, 56, 43]\n",
            "decode - [46, 47, 1, 58, 46, 43, 56, 43]: hi there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwBmtSPqr5J0",
        "outputId": "5385430e-9094-496c-cd04-c06dbbb8d853"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "print(train_data[:block_size + 1])\n",
        "\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size + 1]\n",
        "for i in range(block_size):\n",
        "  context = x[:i + 1]\n",
        "  target = y[i]\n",
        "  print(f'when input is {context} ther target is: {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BTDOCkbtdEH",
        "outputId": "4179f5d4-3173-40c2-c9d2-4d11dd9061c0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n",
            "when input is tensor([18]) ther target is: 47\n",
            "when input is tensor([18, 47]) ther target is: 56\n",
            "when input is tensor([18, 47, 56]) ther target is: 57\n",
            "when input is tensor([18, 47, 56, 57]) ther target is: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) ther target is: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) ther target is: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) ther target is: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) ther target is: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 #parallel processing\n",
        "block_size = 8 #max length of context\n",
        "\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    #random 4 numbers [0,datasize-block_size]\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    #input, pick block_sized pieces, starting at random pos in datatset\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    #labels for these pieces\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    #x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print(f'inputs: {xb.shape} \\n {xb}')\n",
        "print(f'targets: {yb.shape} \\n {yb}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoEEZ84axoN5",
        "outputId": "fe1d875a-2564-48cd-c296-03483ff939a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: torch.Size([4, 8]) \n",
            " tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets: torch.Size([4, 8]) \n",
            " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, covab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    #idx and targets are (B,T) tensor of integer\n",
        "    logits = self.token_embedding_table(idx) #(Batch=4,Time=8,Channel=vocab_size)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "\n",
        "    else:\n",
        "\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets= targets.view(B*T)\n",
        "\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "      # idx is (B, T) array of indices in the current context\n",
        "      for _ in range(max_new_tokens):\n",
        "          # get the predictions\n",
        "          logits, loss = self(idx)\n",
        "          # focus only on the last time step\n",
        "          logits = logits[:, -1, :] # becomes (B, C)\n",
        "          # apply softmax to get probabilities\n",
        "          probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "          # sample from the distribution\n",
        "          idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "          # append sampled index to the running sequence\n",
        "          idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "      return idx\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaFdgnvozRbv",
        "outputId": "4b426b32-6673-4719-da58-2e66aa8677e3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.6208, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens = 100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj_j-1sb1Ryo",
        "outputId": "3a23e94c-2754-4f2a-f8fb-d8505eeb6a7a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " gtFeYzB;YrsAAZH!Pga,aZflmP'FDv'hOVU$kEBYaI-mTyiP?xL!.$U.PyL;nhM !!bQaCZUdJ3ZZH&nQzj\n",
            "CZlkVSdDb\n",
            "o?HJO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "2qCA2Crg6C8q"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "\n",
        "  #sample a batch of data\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # eval loss\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none = True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJk-cRAICvus",
        "outputId": "e34c441c-d2cc-47f6-d5e5-2fe9a71361de"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3433406352996826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens = 500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOuckIblDdyF",
        "outputId": "3ae5d581-f1e9-4617-dcdf-246cf5c51d71"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bolowh\n",
            "Treayousth, wiscous yen.\n",
            "\n",
            "Whatinee'styoimoungo\n",
            "BUERK: bur aintrougsad met INoun'ser Cacow co: twaks'r hississtou' yel llind gr ok s; sthats Thears tuchor ofasthis sthis INTher sth; s IENTASe, frepre mef chede'sthat the me nite beye g, t re GLAnder m stheo u the the fofathendre t thoo brseadassouss r tere; w\n",
            "\n",
            "\n",
            "ADWhese setriesig,\n",
            "APRond ocere iobllescer mile is bey, magher whetat wid;\n",
            "\n",
            "ARINIUCICE y f weat d itit pe thareily stishay f a da aral.\n",
            "Trer. saisevithesthat An d l?\n",
            "Angrur wh reavil\n"
          ]
        }
      ]
    }
  ]
}